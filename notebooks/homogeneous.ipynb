{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Idea #1 - comparison of segregation in Boston vs Philly (now and prior)\n",
    "\n",
    "Ways of measuring:\n",
    "\n",
    "*Compare percent of different geographies (from blocks to ZIP code) that are predominately one race or ethnicity\n",
    "\n",
    "*The same but white vs minority in general\n",
    "\n",
    "*The same as either but also considering population of a tract, and distance to close tract with a predominance that is not your own. Classify the tracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import charts_function_list\n",
    "import os\n",
    "base,data,outputs = charts_function_list.folder_setup()\n",
    "from census import Census\n",
    "from us import states\n",
    "key = key\n",
    "c = Census(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some info on Census and US libraries from \n",
    "\n",
    "https://github.com/datamade/census\n",
    "\n",
    "## Description\n",
    "\n",
    "#### ACS5 \n",
    "state(fields, state_fips)\n",
    "\n",
    "\n",
    "state_county(fields, state_fips, county_fips)\n",
    "\n",
    "\n",
    "state_county_blockgroup(fields, state_fips, county_fips, blockgroup)\n",
    "\n",
    "\n",
    "state_county_subdivision(fields, state_fips, county_fips, subdiv_fips)\n",
    "\n",
    "\n",
    "state_county_tract(fields, state_fips, county_fips, tract)\n",
    "\n",
    "\n",
    "state_place(fields, state_fips, place)\n",
    "\n",
    "\n",
    "state_district(fields, state_fips, district)\n",
    "\n",
    "\n",
    "us(fields)\n",
    "\n",
    "zipcode(fields, zip5)\n",
    "\n",
    "#### ACS1\n",
    "\n",
    "ACS1 Geographies\n",
    "\n",
    "state(fields, state_fips)\n",
    "\n",
    "state_district(fields, state_fips, district)\n",
    "us(fields)\n",
    "\n",
    "\n",
    "## Datasets\n",
    "*acs5: ACS 5 Year Estimates (2016, 2015, 2014, 2013, 2012, 2011, 2010)\n",
    "\n",
    "*acs1dp: ACS 1 Year Estimates, Data Profiles (2016, 2015, 2014, 2013, 2012)\n",
    "\n",
    "*sf1: Census Summary File 1 (2010, 2000, 1990)\n",
    "\n",
    "*sf3: Census Summary File 3 (2000, 1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class state_things(object):\n",
    "    def __init__(self,state_name):\n",
    "        \n",
    "        temp_df = pd.DataFrame(c.acs5.state('NAME', Census.ALL))\n",
    "        self.state_name = state_name\n",
    "        self.state_code = temp_df[temp_df['NAME']==self.state_name]['state'].values[0]\n",
    "        self.county_codes_full = pd.DataFrame(c.acs5.get('NAME', geo={'for': 'county:*',\n",
    "                       'in': 'state:'+self.state_code}))\n",
    "        \n",
    "        self.county_codes = {k:v for k,v in zip(self.county_codes_full['county'],self.county_codes_full['NAME'])}\n",
    "        \n",
    "        \n",
    "    def search_for_county(self,county_name):\n",
    "        return self.county_codes_full[self.county_codes_full['NAME'].str.contains(county_name)]\n",
    "    \n",
    "    \n",
    "        \n",
    "    def get_by_tract(self,county_code,additional_fields=None):\n",
    "        if additional_fields == None:\n",
    "            tract_df = pd.DataFrame(c.acs5.state_county_tract('NAME', self.state_code,county_code, Census.ALL))\n",
    "            \n",
    "        else:\n",
    "            tract_df = pd.DataFrame(c.acs5.state_county_tract(tuple(['NAME'])+tuple(additional_fields), self.state_code,county_code, Census.ALL))\n",
    "      \n",
    "        tract_df['county_map'] = tract_df['county'].map(self.county_codes)\n",
    "        return tract_df\n",
    "        \n",
    "    def get_places(self,additional_fields=None):\n",
    "        if additional_fields == None:\n",
    "            place_df = pd.DataFrame(c.acs5.state_place('NAME',self.state_code, place=Census.ALL))\n",
    "\n",
    "        else:\n",
    "            place_df = pd.DataFrame(c.acs5.state_place((tuple(['NAME'])+tuple(additional_fields)),\n",
    "                                                    self.state_code, place= Census.ALL))\n",
    "        return place_df\n",
    "\n",
    "#find fields in a particular table and return as a dictionary\n",
    "def fields_in_table(table_number):\n",
    "    table_list =  list(filter(lambda x: table_number in x, c.acs5.fields().keys()))\n",
    "    labels = [c.acs5.fields()[x]['label'] for x in table_list]\n",
    "    return {k:v for k,v in zip(table_list,labels)} \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_codes = c.acs5.state('NAME', Census.ALL)\n",
    "state_code_frame = pd.DataFrame(state_codes)\n",
    "d = {name:state_things(name) for name in state_code_frame['NAME']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get necessary fields related to Race by Hispanic/Latino Origin table, B03002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_places = []\n",
    "us_tracts = []\n",
    "\n",
    "#create dictionary to get fields in the Race by Hispanic Origin table\n",
    "hisp_race_dict = fields_in_table(table_number='B03002')\n",
    "\n",
    "#take just the keys to generate the tables\n",
    "fields_we_want = list(hisp_race_dict.keys())\n",
    "\n",
    "for states in list(d.keys()):\n",
    "    #pull all the places for each state\n",
    "    us_places.append(d[states].get_places(additional_fields=fields_we_want))\n",
    "    \n",
    "    for counties in list(d[states].county_codes.keys()):\n",
    "        us_tracts.append(d[states].get_by_tract(county_code=counties,additional_fields=fields_we_want))\n",
    "\n",
    "place_race_frame = pd.concat(us_places).reset_index(drop=True)\n",
    "tract_race_frame = pd.concat(us_tracts).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reformat_race(df,geo):\n",
    "    race_mapping = {'B03002_001E':'TOTAL',\n",
    "                       'B03002_003E':'WHITE', #White = White NH\n",
    "                       'B03002_004E':'BLACK', #Black = Black NH\n",
    "                       'B03002_005E':'AK_NH',\n",
    "                       'B03002_006E':'ASIAN_NH',\n",
    "                       'B03002_007E':'PI_NH',\n",
    "                       'B03002_008E':'OTHER_NH',\n",
    "                       'B03002_009E':'MIX_NH',\n",
    "                       'B03002_012E':'HISP_ALL',\n",
    "                       'B03002_013E':'WHITE_H',\n",
    "                       'B03002_014E':'BLACK_H',\n",
    "                       'B03002_015E':'AK_H',\n",
    "                       'B03002_016E':'ASIAN_H',\n",
    "                       'B03002_017E':'PI_H',\n",
    "                       'B03002_018E':'OTHER_H',\n",
    "                       'B03002_019E':'MIX_H'}\n",
    "    df = df.rename(columns=race_mapping)\n",
    "    if geo == 'place':\n",
    "        df = df[list(race_mapping.values())+['NAME', 'place', 'state']]\n",
    "    elif geo == 'tract':\n",
    "         df = df[list(race_mapping.values())+['NAME', 'tract', 'state','county_map']]\n",
    "    \n",
    "    df['AK'] = df['AK_NH']+df['AK_H']\n",
    "    df['API']= df['ASIAN_H']+df['ASIAN_NH']+df['PI_H']+df['PI_NH']\n",
    "    df['OTHER_MIX']=df['OTHER_NH']+df['MIX_NH']\n",
    "    df['HISP'] = df['HISP_ALL']-df['AK_H']-df['PI_H']-df['ASIAN_H']\n",
    "    def percent_group(column):\n",
    "        return df[column]/df['TOTAL']\n",
    "    \n",
    "    percent_frame = pd.DataFrame({'PER_WHITE':percent_group('WHITE'),\n",
    "                                 'PER_BLACK':percent_group('BLACK'),\n",
    "                                 'PER_API':percent_group('API'),\n",
    "                                 'PER_AKNA':percent_group('AK'),\n",
    "                                  'PER_HISP':percent_group('HISP'),\n",
    "                                  'PER_OTHER':percent_group('OTHER_MIX')\n",
    "                                 \n",
    "                                 })\n",
    "    \n",
    "    df = pd.merge(df,percent_frame,left_index=True,right_index=True)\n",
    "    df['MAX_ETH_PER']= percent_frame.max(axis=1)\n",
    "    df['MAX_ETH']= percent_frame.idxmax(axis=1)\n",
    "    \n",
    "    def threshold_percent(threshold):\n",
    "         return np.where(df['MAX_ETH_PER']>=threshold,1,0)\n",
    "    \n",
    "    df['Above 70'],df['Above 80'],df['Above 90']=threshold_percent(.7),threshold_percent(.8),threshold_percent(.9)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_race_frame_full = reformat_race(place_race_frame,geo='place').sort_values(by='MAX_ETH_PER',ascending=False)\n",
    "tract_race_frame_full = reformat_race(tract_race_frame,geo='tract').sort_values(by='MAX_ETH_PER',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(data)\n",
    "place_race_frame_full.to_csv('2016_ACS_race_place_full.csv')\n",
    "tract_race_frame_full.to_csv('2016_ACS_race_tract_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting what cities to feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOST PER_WHITE: Portland city, Oregon\n",
      "MOST PER_BLACK: Detroit city, Michigan\n",
      "MOST PER_HISP: El Paso city, Texas\n",
      "MOST PER_API: San Jose city, California\n",
      "---\n",
      "No place over 500,000K with majorirty AK/Native American or Other/Mixed Race. Finding the max perctages instead\n",
      "---\n",
      "PER_AK:  Albuquerque city, New Mexico\n",
      "PER_OTHER:  Seattle city, Washington\n"
     ]
    }
   ],
   "source": [
    "ak_max = place_race_frame_full[(place_race_frame_full['TOTAL']>500000)]['PER_AKNA'].max()\n",
    "per_other_max = place_race_frame_full[(place_race_frame_full['TOTAL']>500000)]['PER_OTHER'].max()\n",
    "\n",
    "\n",
    "def max_print(group, minimum):\n",
    "    print('MOST '+group+\": \"+place_race_frame_full[(place_race_frame_full['MAX_ETH']==group)&(place_race_frame_full['TOTAL']>minimum)].reset_index().loc[0]['NAME'])\n",
    "\n",
    "for item in ['PER_WHITE','PER_BLACK','PER_HISP','PER_API']:\n",
    "    max_print(item,500000)\n",
    "    \n",
    "print(\"---\")    \n",
    "print(\"No place over 500,000K with majorirty AK/Native American or Other/Mixed Race. Finding the max perctages instead\")\n",
    "print(\"---\")\n",
    "print('PER_AK: ',place_race_frame_full[place_race_frame_full['PER_AKNA']==ak_max].reset_index().loc[0]['NAME'])\n",
    "print('PER_OTHER: ',place_race_frame_full[place_race_frame_full['PER_OTHER']==per_other_max].reset_index().loc[0]['NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#percent of population that lives in a tract that is >=x% of one ethnic group\n",
    "def homogenous_pop(df,threshold_column):\n",
    "    percent = (df[df[threshold_column]==1]['TOTAL'].sum())/df['TOTAL'].sum()\n",
    "    return format(percent*100,'.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For those who are non-white and Hispanic, which to include within the \"hispanic\" group? Let's assess\n",
    "\n",
    "for counties in [reformat_race(la_county_data), reformat_race(philly_county_data),reformat_race(suffolk_county_data)]:\n",
    "    for item in ['White_H','Black_H','AK_H','Asian_H','PI_H','OTHER_H','MIX_H']:\n",
    "        print(item+' '+str(format(((counties[item]/counties['HISP_All']).mean())*100,'.1f'))+'%')\n",
    "    print('------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## extra tutorial stuff\n",
    "\n",
    "c.acs5.get(('NAME', table_name),\n",
    "          {'for': 'state:{}'.format(states.MD.fips)},year=2011) #set different years\n",
    "\n",
    "\n",
    "\n",
    "table_name ='B25034_010E'\n",
    "\n",
    "#The get method is the core data access method on both the ACS and SF1 data sets. \n",
    "#The first parameter is either a single string column or a tuple of columns. \n",
    "#The second parameter is a geoemtry dict with a for key and on option in key. \n",
    "c.acs5.get(('NAME', table_name),\n",
    "          {'for': 'state:{}'.format(states.MD.fips)},year=2011) #set different years"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
